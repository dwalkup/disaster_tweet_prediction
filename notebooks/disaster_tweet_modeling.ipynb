{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets\n",
    "\n",
    "This notebook is used for modeling of the cleaned and preprocessed dataset from the Kaggle competition \"Real or Not? NLP with Disaster Tweets\" located here: https://www.kaggle.com/c/nlp-getting-started/overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# helper functions\n",
    "import helpers\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training and testing data from files.\n",
    "#### Read the training data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    keyword                                               text  target\n",
       "0   1  nokeyword  our deeds are the reason of this earthquake ma...       1\n",
       "1   4  nokeyword              forest fire near la ronge sask canada       1\n",
       "2   5  nokeyword  all residents asked to shelter in place are be...       1\n",
       "3   6  nokeyword  people receive wildfires evacuation orders in ...       1\n",
       "4   7  nokeyword  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame for stemmed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/stemmed_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>our deed are the reason of thi earthquak may a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>all resid ask to shelter in place are be notif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>peopl receiv wildfir evacu order in california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>just got sent thi photo from rubi alaska as sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    keyword                                               text  target\n",
       "0   1  nokeyword  our deed are the reason of thi earthquak may a...       1\n",
       "1   4  nokeyword               forest fire near la rong sask canada       1\n",
       "2   5  nokeyword  all resid ask to shelter in place are be notif...       1\n",
       "3   6  nokeyword     peopl receiv wildfir evacu order in california       1\n",
       "4   7  nokeyword  just got sent thi photo from rubi alaska as sm...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame for lemmatized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/lemmatized_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>our deed are the reason of this earthquake may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>all resident asked to shelter in place are bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>just got sent this photo from ruby alaska a sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    keyword                                               text  target\n",
       "0   1  nokeyword  our deed are the reason of this earthquake may...       1\n",
       "1   4  nokeyword              forest fire near la ronge sask canada       1\n",
       "2   5  nokeyword  all resident asked to shelter in place are bei...       1\n",
       "3   6  nokeyword  people receive wildfire evacuation order in ca...       1\n",
       "4   7  nokeyword  just got sent this photo from ruby alaska a sm...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the testing data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>heard about earthquake is different city stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>there is a forest fire at spot pond goose are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>typhoon soudelor kill in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    keyword    location  \\\n",
       "0   0  nokeyword  nolocation   \n",
       "1   2  nokeyword  nolocation   \n",
       "2   3  nokeyword  nolocation   \n",
       "3   9  nokeyword  nolocation   \n",
       "4  11  nokeyword  nolocation   \n",
       "\n",
       "                                                text  \n",
       "0                 just happened a terrible car crash  \n",
       "1  heard about earthquake is different city stay ...  \n",
       "2  there is a forest fire at spot pond goose are ...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4          typhoon soudelor kill in china and taiwan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good does my model have to be to outperform the naive approach (i.e., no tweet is about a disaster)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class probabilities:  {0: 0.5737136763529725, 1: 0.42628632364702745} \n",
      "Chance tweet is not about a real disaster:  0.5737\n"
     ]
    }
   ],
   "source": [
    "p_classes = dict(train_df['target'].value_counts(normalize=True))\n",
    "naive_approach = p_classes[0]\n",
    "print('Class probabilities: ', p_classes,\n",
    "      '\\nChance tweet is not about a real disaster: ', np.round(naive_approach, decimals = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a DataFrame to hold scoring information, for final model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_df = pd.DataFrame(columns = ['Model', 'Vectorizer', 'Text_Treatment', 'Mean_F1_Score', 'F1_Std_Dev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging using sklearn CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of experiments will include stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                   ngram_range = (1, 2),\n",
    "                                   binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression on CountVectorizer treated training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6382107580107526 +/- 0.05755892959272567\n"
     ]
    }
   ],
   "source": [
    "# LogReg, raw\n",
    "clf_lr = LogisticRegressionCV(class_weight = 'balanced',\n",
    "                              random_state = 42)\n",
    "\n",
    "scores = cross_val_score(clf_lr,\n",
    "                         lr_train_vectors, train_df[\"target\"],\n",
    "                         cv=5,\n",
    "                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                                     'None', clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vector_stem = count_vectorizer.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.647272547233625 +/- 0.05912689198763571\n"
     ]
    }
   ],
   "source": [
    "# LogReg, stemmed\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_vector_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                                     'Stemmed', clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vector_lemma = count_vectorizer.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6554592142449882 +/- 0.048466482009136516\n"
     ]
    }
   ],
   "source": [
    "# LogReg, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_vector_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                                     'Lemmatized', clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second set of experiments will remove stop words, to see if that improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = stopwords.words('english')\n",
    "count_vectorizer_no_stops = CountVectorizer(strip_accents = 'unicode',\n",
    "                                            stop_words = english_stops,\n",
    "                                            ngram_range = (1, 2),\n",
    "                                            binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vector_no_stops = count_vectorizer_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5998213558149595 +/- 0.07525380294906855\n"
     ]
    }
   ],
   "source": [
    "# LogReg, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_vector_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                             'Removed stopwords', clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vector_stem_no_stops = count_vectorizer_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6073351791553622 +/- 0.0706929906869057\n"
     ]
    }
   ],
   "source": [
    "# LogReg, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_vector_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                                     'Removed stopwords, stemmed', clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_vector_lemma_no_stops = count_vectorizer_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6080859128072598 +/- 0.06530945915867539\n"
     ]
    }
   ],
   "source": [
    "# LogReg, lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_vector_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'CountVectorizer',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes on CountVectorizer treated training data\n",
    "\n",
    "First set of experiments includes stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6749567532885051 +/- 0.0388777822155517\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "clf_mnb = MultinomialNB()\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vectors, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vector_stem = count_vectorizer.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.679516177528353 +/- 0.04514210200517351\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, stemmed\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'Stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vector_lemma = count_vectorizer.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6838672747769288 +/- 0.04188014881745761\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'Lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second set of experiments excludes stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vector_no_stops = count_vectorizer_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6600585905094238 +/- 0.04066299988918634\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vector_stem_no_stops = count_vectorizer_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6593484695899581 +/- 0.04559206635857508\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'Removed stopwords, stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_vector_lemma_no_stops = count_vectorizer_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6607353953919963 +/- 0.04315073975283043\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'CountVectorizer',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and term frequency weighting using TD-IDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first set of experiments, I did not remove stopwords from the tweets to get a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 1),\n",
    "                         max_df=0.5,\n",
    "                         min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second set of experiments using TF-IDF term weighting, I removed the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_no_stops = TfidfVectorizer(stop_words = english_stops,\n",
    "                                  ngram_range=(1, 1),\n",
    "                                  max_df=0.5,\n",
    "                                  min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression on TF-IDF treated training data\n",
    "The first set of experiments includes stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf = tf_idf.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6661062126913281 +/- 0.036940176833570974\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf_stem = tf_idf.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.672782226487904 +/- 0.043425305750678725\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, stemmed\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'Stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf_lemma = tf_idf.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6741968290118585 +/- 0.04037677659541278\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'Lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second set of experiments, excluding stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf_no_stops = tf_idf_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6286092341566316 +/- 0.054729023589583974\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf_stem_no_stops = tf_idf_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6350515980527547 +/- 0.0538273658163454\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords, stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_tfidf_lemma_no_stops = tf_idf_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6253084385157027 +/- 0.05239536927812601\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression, lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'LogisticRegression', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes on TF-IDF treated training data\n",
    "First set of experiments includes stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf = tf_idf.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6554771472834363 +/- 0.05697076934045421\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf_stem = tf_idf.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6601653543759294 +/- 0.06010001540846695\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, stemmed\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'Stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf_lemma = tf_idf.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6617217901213649 +/- 0.055086839634722246\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'Lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second set of experiments excludes stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf_no_stops = tf_idf_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6478170987485605 +/- 0.054678210710489006\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf_stem_no_stops = tf_idf_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6466233450531924 +/- 0.05253238685817721\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords, stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_train_tfidf_lemma_no_stops = tf_idf_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6514290195889771 +/- 0.05372415943963887\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes, lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_tfidf_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'MultinomialNB', 'TfidfVectorizer',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Models\n",
    "I used cross-validation to determine the parameters for all SVM models.\n",
    "\n",
    "The cross-validation steps were commented out for subsequent runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameter grid for GridSearchCV testing\n",
    "\n",
    "# my_params = {'C': [0.1, 0.3, 0.5, 0.7],\n",
    "#              'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "#              'degree': [2, 3],\n",
    "#              'gamma' : ['auto', 'scale'],\n",
    "#              'class_weight' : ['balanced'],\n",
    "#              'random_state' : [42],\n",
    "#              'probability' : [False, True],\n",
    "# #              'shrinking' : [False, True],\n",
    "#              'coef0' : [1e2, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV testing to find best parameters for SVM model\n",
    "\n",
    "# scorer = make_scorer(f1_score)\n",
    "# gs_clf = GridSearchCV(svm.SVC(),\n",
    "#                       param_grid = my_params,\n",
    "#                       scoring = scorer,\n",
    "#                       verbose = 1,\n",
    "#                       n_jobs = -1)\n",
    "# gs_clf.fit(train_tfidf_lemmatized_df, train_df[\"target\"])\n",
    "# print(gs_clf.best_params_, gs_clf.best_score_)\n",
    "\n",
    "# results:\n",
    "# {'C': 0.7,\n",
    "#  'class_weight': 'balanced',\n",
    "#  'coef0': 1,\n",
    "#  'degree': 2,\n",
    "#  'gamma': 'scale',\n",
    "#  'kernel': 'sigmoid',\n",
    "#  'probability': False,\n",
    "#  'random_state': 42}\n",
    "# 0.6660730647063914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of experiments, stopwords included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6220429414287023 +/- 0.054198296393284176\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, raw\n",
    "clf_svc = svm.SVC(C = 0.7,\n",
    "              kernel = 'sigmoid',\n",
    "              degree = 2,\n",
    "              gamma = 'scale',\n",
    "              class_weight = 'balanced',\n",
    "              random_state = 42)\n",
    "\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vectors, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vector_stem = count_vectorizer.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6254624286427328 +/- 0.060756941849000864\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, stemmed\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vector_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'Stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vector_lemma = count_vectorizer.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6260344777884835 +/- 0.05547480826584965\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vector_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'Lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second set of experiments, stopwords excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vector_no_stops = count_vectorizer_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5618171000875449 +/- 0.07958271063671964\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vector_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vector_stem_no_stops = count_vectorizer_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5778955905702369 +/- 0.07855708276207068\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vector_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'Removed stopwords, stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_vector_lemma_no_stops = count_vectorizer_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5780322604386756 +/- 0.083309277078992\n"
     ]
    }
   ],
   "source": [
    "# SVM: CountVectorizer, lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(clf_svc,\n",
    "                                         svc_train_vector_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'CountVectorizer',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I did an additional set of experiments with SVM, using LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA (Latent Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components = 100, random_state = 42)\n",
    "normalizer = preprocessing.Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf = tf_idf.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first set of experiments included stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.636551666183974 +/- 0.02857727978377457\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF, raw\n",
    "pipe = pipeline.make_pipeline(svd, normalizer, clf_svc)\n",
    "\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf_stem = tf_idf.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6504114464890122 +/- 0.028527018696461192\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF, stemmed\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_stem, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'Stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf_lemma = tf_idf.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6504652425493024 +/- 0.028734184112966354\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF, lemmatized\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'Lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second set of experiments excluded stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf_no_stops = tf_idf_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.643623061477675 +/- 0.025487617825243267\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF, raw, no stopwords\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf_stem_no_stops = tf_idf_no_stops.fit_transform(stemmed_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6345721741716062 +/- 0.025811774109053245\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF, stemmed, no stopwords\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_stem_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'Removed stopwords, stemmed',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_tfidf_lemma_no_stops = tf_idf_no_stops.fit_transform(lemmatized_train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.6298568062119483 +/- 0.03924782445307571\n"
     ]
    }
   ],
   "source": [
    "# SVM: LSA, TF-IDF,lemmatized, no stopwords\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_lemma_no_stops, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'SVM', 'LSA',\n",
    "                                     'Removed stopwords, lemmatized',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Models\n",
    "\n",
    "I also tried a couple of KNN models, but the results weren't promising. Their scores were both below the naive approach threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_tfidf = tf_idf.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5198641468784797 +/- 0.04564133695115445\n"
     ]
    }
   ],
   "source": [
    "# LSA -> KNN: TF-IDF, raw\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5,\n",
    "                               algorithm='brute',\n",
    "                               metric='cosine')\n",
    "\n",
    "pipe = pipeline.make_pipeline(svd, normalizer, clf_knn)\n",
    "\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         knn_train_tfidf, train_df['target'],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'KNN', 'LSA',\n",
    "                                     'None',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_tfidf_no_stops = tf_idf_no_stops.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.5589305021316724 +/- 0.041042963510106854\n"
     ]
    }
   ],
   "source": [
    "# KNN: LSA, TF-IDF, no stopwords\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         knn_train_tfidf_no_stops, train_df['target'],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "\n",
    "clf_score = helpers.model_scoring(scores)\n",
    "\n",
    "scoring_df = helpers.score_recording(scoring_df, 'KNN', 'LSA',\n",
    "                                     'Removed stopwords',\n",
    "                                     clf_score[0], clf_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Model Scores\n",
    "This table is sorted by the mean F1 score of each model, to help me select the final model(s) for submission to the contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Text_Treatment</th>\n",
       "      <th>Mean_F1_Score</th>\n",
       "      <th>F1_Std_Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.683867</td>\n",
       "      <td>0.041880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.679516</td>\n",
       "      <td>0.045142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.674957</td>\n",
       "      <td>0.038878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.674197</td>\n",
       "      <td>0.040377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.672782</td>\n",
       "      <td>0.043425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.666106</td>\n",
       "      <td>0.036940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.661722</td>\n",
       "      <td>0.055087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.660735</td>\n",
       "      <td>0.043151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.660165</td>\n",
       "      <td>0.060100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.660059</td>\n",
       "      <td>0.040663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.659348</td>\n",
       "      <td>0.045592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.655477</td>\n",
       "      <td>0.056971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.655459</td>\n",
       "      <td>0.048466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.053724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.650465</td>\n",
       "      <td>0.028734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.650411</td>\n",
       "      <td>0.028527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.647817</td>\n",
       "      <td>0.054678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.647273</td>\n",
       "      <td>0.059127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.646623</td>\n",
       "      <td>0.052532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.643623</td>\n",
       "      <td>0.025488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.057559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>None</td>\n",
       "      <td>0.636552</td>\n",
       "      <td>0.028577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.635052</td>\n",
       "      <td>0.053827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.634572</td>\n",
       "      <td>0.025812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.629857</td>\n",
       "      <td>0.039248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.628609</td>\n",
       "      <td>0.054729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Lemmatized</td>\n",
       "      <td>0.626034</td>\n",
       "      <td>0.055475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Stemmed</td>\n",
       "      <td>0.625462</td>\n",
       "      <td>0.060757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.625308</td>\n",
       "      <td>0.052395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.622043</td>\n",
       "      <td>0.054198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.608086</td>\n",
       "      <td>0.065309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.607335</td>\n",
       "      <td>0.070693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.599821</td>\n",
       "      <td>0.075254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, lemmatized</td>\n",
       "      <td>0.578032</td>\n",
       "      <td>0.083309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords, stemmed</td>\n",
       "      <td>0.577896</td>\n",
       "      <td>0.078557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.561817</td>\n",
       "      <td>0.079583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KNN</td>\n",
       "      <td>LSA</td>\n",
       "      <td>Removed stopwords</td>\n",
       "      <td>0.558931</td>\n",
       "      <td>0.041043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KNN</td>\n",
       "      <td>LSA</td>\n",
       "      <td>None</td>\n",
       "      <td>0.519864</td>\n",
       "      <td>0.045641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model       Vectorizer                 Text_Treatment  \\\n",
       "8        MultinomialNB  CountVectorizer                     Lemmatized   \n",
       "7        MultinomialNB  CountVectorizer                        Stemmed   \n",
       "6        MultinomialNB  CountVectorizer                           None   \n",
       "14  LogisticRegression  TfidfVectorizer                     Lemmatized   \n",
       "13  LogisticRegression  TfidfVectorizer                        Stemmed   \n",
       "12  LogisticRegression  TfidfVectorizer                           None   \n",
       "20       MultinomialNB  TfidfVectorizer                     Lemmatized   \n",
       "11       MultinomialNB  CountVectorizer  Removed stopwords, lemmatized   \n",
       "19       MultinomialNB  TfidfVectorizer                        Stemmed   \n",
       "9        MultinomialNB  CountVectorizer              Removed stopwords   \n",
       "10       MultinomialNB  CountVectorizer     Removed stopwords, stemmed   \n",
       "18       MultinomialNB  TfidfVectorizer                           None   \n",
       "2   LogisticRegression  CountVectorizer                     Lemmatized   \n",
       "23       MultinomialNB  TfidfVectorizer  Removed stopwords, lemmatized   \n",
       "32                 SVM              LSA                     Lemmatized   \n",
       "31                 SVM              LSA                        Stemmed   \n",
       "21       MultinomialNB  TfidfVectorizer              Removed stopwords   \n",
       "1   LogisticRegression  CountVectorizer                        Stemmed   \n",
       "22       MultinomialNB  TfidfVectorizer     Removed stopwords, stemmed   \n",
       "33                 SVM              LSA              Removed stopwords   \n",
       "0   LogisticRegression  CountVectorizer                           None   \n",
       "30                 SVM              LSA                           None   \n",
       "16  LogisticRegression  TfidfVectorizer     Removed stopwords, stemmed   \n",
       "34                 SVM              LSA     Removed stopwords, stemmed   \n",
       "35                 SVM              LSA  Removed stopwords, lemmatized   \n",
       "15  LogisticRegression  TfidfVectorizer              Removed stopwords   \n",
       "26                 SVM  CountVectorizer                     Lemmatized   \n",
       "25                 SVM  CountVectorizer                        Stemmed   \n",
       "17  LogisticRegression  TfidfVectorizer  Removed stopwords, lemmatized   \n",
       "24                 SVM  CountVectorizer                           None   \n",
       "5   LogisticRegression  CountVectorizer  Removed stopwords, lemmatized   \n",
       "4   LogisticRegression  CountVectorizer     Removed stopwords, stemmed   \n",
       "3   LogisticRegression  CountVectorizer              Removed stopwords   \n",
       "29                 SVM  CountVectorizer  Removed stopwords, lemmatized   \n",
       "28                 SVM  CountVectorizer     Removed stopwords, stemmed   \n",
       "27                 SVM  CountVectorizer              Removed stopwords   \n",
       "37                 KNN              LSA              Removed stopwords   \n",
       "36                 KNN              LSA                           None   \n",
       "\n",
       "    Mean_F1_Score  F1_Std_Dev  \n",
       "8        0.683867    0.041880  \n",
       "7        0.679516    0.045142  \n",
       "6        0.674957    0.038878  \n",
       "14       0.674197    0.040377  \n",
       "13       0.672782    0.043425  \n",
       "12       0.666106    0.036940  \n",
       "20       0.661722    0.055087  \n",
       "11       0.660735    0.043151  \n",
       "19       0.660165    0.060100  \n",
       "9        0.660059    0.040663  \n",
       "10       0.659348    0.045592  \n",
       "18       0.655477    0.056971  \n",
       "2        0.655459    0.048466  \n",
       "23       0.651429    0.053724  \n",
       "32       0.650465    0.028734  \n",
       "31       0.650411    0.028527  \n",
       "21       0.647817    0.054678  \n",
       "1        0.647273    0.059127  \n",
       "22       0.646623    0.052532  \n",
       "33       0.643623    0.025488  \n",
       "0        0.638211    0.057559  \n",
       "30       0.636552    0.028577  \n",
       "16       0.635052    0.053827  \n",
       "34       0.634572    0.025812  \n",
       "35       0.629857    0.039248  \n",
       "15       0.628609    0.054729  \n",
       "26       0.626034    0.055475  \n",
       "25       0.625462    0.060757  \n",
       "17       0.625308    0.052395  \n",
       "24       0.622043    0.054198  \n",
       "5        0.608086    0.065309  \n",
       "4        0.607335    0.070693  \n",
       "3        0.599821    0.075254  \n",
       "29       0.578032    0.083309  \n",
       "28       0.577896    0.078557  \n",
       "27       0.561817    0.079583  \n",
       "37       0.558931    0.041043  \n",
       "36       0.519864    0.045641  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_df.sort_values(by = 'Mean_F1_Score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final models\n",
    "I used the highest-scoring version of each model type (Logistic Regression, Multinomial Naive Bayes, Support Vector Machine) to create submissions for the Kaggle contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741968290118585 +/- 0.04037677659541278\n"
     ]
    }
   ],
   "source": [
    "# Final models - Logistic Regression, lemmatized\n",
    "scores = model_selection.cross_val_score(clf_lr,\n",
    "                                         lr_train_tfidf_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "mean_score = scores.mean()\n",
    "stability = scores.std()\n",
    "print(mean_score, '+/-', stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.fit(lemmatized_train_df['text'])\n",
    "test_tfidf_lemma = tf_idf.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7502, 5578)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_tfidf_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 5578)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.fit(lr_train_tfidf_lemma, train_df[\"target\"])\n",
    "lr_preds = clf_lr.predict(test_tfidf_lemma)\n",
    "lr_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6838672747769288 +/- 0.04188014881745761\n"
     ]
    }
   ],
   "source": [
    "# Final models - Multinomial Bayes, lemmatized\n",
    "# this was the best model (Kaggle score: 0.80777)\n",
    "\n",
    "scores = model_selection.cross_val_score(clf_mnb,\n",
    "                                         mnb_train_vector_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "mean_score = scores.mean()\n",
    "stability = scores.std()\n",
    "print(mean_score, '+/-', stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer.fit(lemmatized_train_df['text'])\n",
    "test_vector_lemma = count_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7502, 68135)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_train_vector_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 68135)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnb.fit(mnb_train_vector_lemma, train_df[\"target\"])\n",
    "mnb_preds = clf_mnb.predict(test_vector_lemma)\n",
    "mnb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504652425493024 +/- 0.028734184112966354\n"
     ]
    }
   ],
   "source": [
    "# Final models - SVM: LSA, TFIDF, lemmatized\n",
    "pipe = pipeline.make_pipeline(svd, normalizer, clf_svc)\n",
    "\n",
    "scores = model_selection.cross_val_score(pipe,\n",
    "                                         svc_train_tfidf_lemma, train_df[\"target\"],\n",
    "                                         cv=5,\n",
    "                                         scoring=\"f1\")\n",
    "mean_score = scores.mean()\n",
    "stability = scores.std()\n",
    "print(mean_score, '+/-', stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.fit(lemmatized_train_df['text'])\n",
    "test_tfidf_svc_lemma = tf_idf.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7502, 5578)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_train_tfidf_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 5578)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_svc_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc.fit(svc_train_tfidf_lemma, train_df[\"target\"])\n",
    "svc_preds = clf_svc.predict(test_tfidf_svc_lemma)\n",
    "svc_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission for Logistic Regression predictions\n",
    "# model_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "# model_sub['target'] = lr_preds\n",
    "# model_sub.to_csv('../data/lr_prediction_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission for Multinomial Naive Bayes predictions\n",
    "# this one got the best Kaggle score: 0.80777\n",
    "# model_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "# model_sub['target'] = mnb_preds\n",
    "# model_sub.to_csv('../data/mnb_prediction_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission for SVM predictions\n",
    "# model_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "# model_sub['target'] = svc_preds\n",
    "# model_sub.to_csv('../data/svc_prediction_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "There are still some things I can try with these models in order to improve them:\n",
    "* Vary the number of components in the LSA models\n",
    "* More/better tuning of hyperparameters in all models\n",
    "\n",
    "As well, I would like to test TensorFlow & BERT in a Kaggle notebook w/GPU turned on to see how it performs on this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
