{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets\n",
    "\n",
    "This notebook is used for data exploration and preprocessing of the dataset used in the Kaggle competition _\"Real or Not? NLP with Disaster Tweets\"_ located here: https://www.kaggle.com/c/nlp-getting-started/overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwalkup/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text preprocessing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "#helper functions\n",
    "import helpers\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit for the abbreviation list below, and the function that follows: _Up-to-date list of Slangs for Text Preprocessing by @nmaguette_ (https://www.kaggle.com/nmaguette/up-to-date-slangs-conversion-for-text-processing/)\n",
    "\n",
    "These abbreviations and the accompanying function are used to translate common slang or texting/tweeting abbreviations into full words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "    \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbrev(word):\n",
    "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training and test data from files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, read the training data from file and look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data\n",
    "train_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at how many rows and columns, as well as basic information about the training data.\n",
    "* There are 7613 rows and 5 columns.\n",
    "* There are missing values in the 'keyword' and 'location' fields.\n",
    "* The 'id' and 'target' fields are integer data; the rest are string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now read the test data from file and look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "test_df = pd.read_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at basic information for the testing data:\n",
    "* There are 3263 rows and 4 columns (no 'target' column).\n",
    "* There are missing values in the 'keyword' and 'location' columns.\n",
    "* The 'id' column is integer data; the rest are string data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the target balanced?\n",
    "To see, I plotted the value counts of each target class. Class 1 accounts less than half of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(train_df['target'].value_counts().index, train_df['target'].value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sample of training and test data\n",
    "To get a feel for the data, I looked at a random sample from both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2078</td>\n",
       "      <td>casualty</td>\n",
       "      <td>Trinity, Bailiwick of Jersey</td>\n",
       "      <td>@ScriptetteSar @katiecool447 btw the 30th is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>10173</td>\n",
       "      <td>violent%20storm</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Violent Forces Radio: Now Playing Agony - Stor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>7350</td>\n",
       "      <td>obliterate</td>\n",
       "      <td>Korea</td>\n",
       "      <td>@realDonaldTrump to obliterate notion &amp;amp; pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>3136</td>\n",
       "      <td>debris</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>Experts leave lab as Malaysia confirms debris ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>3045</td>\n",
       "      <td>death</td>\n",
       "      <td>Home of the Takers.</td>\n",
       "      <td>Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          keyword                      location  \\\n",
       "1442   2078         casualty  Trinity, Bailiwick of Jersey   \n",
       "7100  10173  violent%20storm                     Worldwide   \n",
       "5153   7350       obliterate                         Korea   \n",
       "2188   3136           debris               Berlin, Germany   \n",
       "2119   3045            death           Home of the Takers.   \n",
       "\n",
       "                                                   text  target  \n",
       "1442  @ScriptetteSar @katiecool447 btw the 30th is a...       1  \n",
       "7100  Violent Forces Radio: Now Playing Agony - Stor...       0  \n",
       "5153  @realDonaldTrump to obliterate notion &amp; pa...       0  \n",
       "2188  Experts leave lab as Malaysia confirms debris ...       1  \n",
       "2119       Y'all PUSSSSSSSSSY AND SHOOOK TO DEATH OF ME       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>378</td>\n",
       "      <td>annihilation</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>U.S National Park Services Tonto National Fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>6720</td>\n",
       "      <td>lava</td>\n",
       "      <td>somewhere over the rainbow</td>\n",
       "      <td>I lava you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1743</td>\n",
       "      <td>buildings%20burning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@chistate33 @thehill What hate crimes? It's th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>5453</td>\n",
       "      <td>first%20responders</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Every time I get on the news I see more sadnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>515</td>\n",
       "      <td>army</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id              keyword                    location  \\\n",
       "115    378         annihilation                     Arizona   \n",
       "1995  6720                 lava  somewhere over the rainbow   \n",
       "533   1743  buildings%20burning                         NaN   \n",
       "1620  5453   first%20responders                      Nevada   \n",
       "157    515                 army                         NaN   \n",
       "\n",
       "                                                   text  \n",
       "115   U.S National Park Services Tonto National Fore...  \n",
       "1995                                         I lava you  \n",
       "533   @chistate33 @thehill What hate crimes? It's th...  \n",
       "1620  Every time I get on the news I see more sadnes...  \n",
       "157   VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the training data.\n",
    "Even at first glance, it's apparent this data will need a lot of processing to get it ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are duplicated tweets, so I dropped the duplicates.\n",
    "This is especially important because several of the duplicate entries were classed differently, which will interfere with model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>68</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>165</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>US</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>172</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>238</td>\n",
       "      <td>airplane%20accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experts in France begin examining airplane deb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>898</td>\n",
       "      <td>bioterrorism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To fight bioterrorism sir.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>10855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evacuation order lifted for town of Roosevelt:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>10867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#stormchase Violent Record Breaking EF-5 El Re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              keyword        location  \\\n",
       "48       68               ablaze  Live On Webcam   \n",
       "115     165           aftershock              US   \n",
       "119     172           aftershock     Switzerland   \n",
       "164     238  airplane%20accident             NaN   \n",
       "624     898         bioterrorism             NaN   \n",
       "...     ...                  ...             ...   \n",
       "7600  10855                  NaN             NaN   \n",
       "7607  10867                  NaN             NaN   \n",
       "7609  10870                  NaN             NaN   \n",
       "7610  10871                  NaN             NaN   \n",
       "7611  10872                  NaN             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "48    Check these out: http://t.co/rOI2NSmEJJ http:/...       0  \n",
       "115   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...       0  \n",
       "119   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/TH...       0  \n",
       "164   Experts in France begin examining airplane deb...       1  \n",
       "624                          To fight bioterrorism sir.       0  \n",
       "...                                                 ...     ...  \n",
       "7600  Evacuation order lifted for town of Roosevelt:...       1  \n",
       "7607  #stormchase Violent Record Breaking EF-5 El Re...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "\n",
       "[110 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df.duplicated(subset = 'text') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(subset = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a copy of the training data to work on.\n",
    "This isn't strictly necessary. I could have worked directly on the training data instead of a copy. I thought it might be useful to retain the original data for comparison purposes, so I made a copy to do my processing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First replace abbreviations in the text field.\n",
    "I started by replacing the abbreviations and acronyms in the tweets with full words. This will give me more accurate term weights when I get to that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df['text'] = cleaned_train_df['text'].apply(lambda x: convert_abbrev(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the tweets' \"text\" field.\n",
    "There are a lot of things in the \"text\" field that don't really provide any information for the purpose of predicting the purpose of the tweets.\n",
    "\n",
    "This includes hyperlinks, HTML tags, punctuation, numbers, words that have numbers inside them, and \"stop words.\" Stop words are words that are commonly used, but don't really provide meaning by themselves, like \"the,\" \"or,\" and \"that.\"\n",
    "\n",
    "A quick glance also reveals misspelled words. Time constraints prevented me from trying to correct spellings; I may look for a spelling checker and return to this later.\n",
    "\n",
    "For this purpose, I wrote a function to clean the text, _\"text_cleaner,\"_ which can be found in the _\"helpers.py\"_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df['text'] = cleaned_train_df['text'].apply(lambda x: helpers.text_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, replace missing keyword entries.\n",
    "I didn't replace the missing \"location\" entries because the cardinality was very high, which lead me to discard location as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keyword = cleaned_train_df.loc[cleaned_train_df['keyword'].isna() == True].index\n",
    "cleaned_train_df['keyword'].loc[no_keyword] = 'no_keyword'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now clean the keyword field.\n",
    "Once the missing entries were replaced with 'no_keyword,' the entries were cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df['keyword'] = cleaned_train_df['keyword'].apply(lambda x: helpers.text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>9226</td>\n",
       "      <td>suicide bombing</td>\n",
       "      <td>Australia</td>\n",
       "      <td>erdogans bloody gambit on july a suicide bombi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>3355</td>\n",
       "      <td>demolition</td>\n",
       "      <td>USA</td>\n",
       "      <td>epa begins demolition of homes in toxic area b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5810</th>\n",
       "      <td>8292</td>\n",
       "      <td>rubble</td>\n",
       "      <td>Columbus, Georgia</td>\n",
       "      <td>refuse to let my life be reduced to rubble whe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1769</td>\n",
       "      <td>buildings burning</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>watching xela firefighters struggle to save bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>2664</td>\n",
       "      <td>crush</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ina buted girl crush</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword           location  \\\n",
       "6450  9226    suicide bombing          Australia   \n",
       "2331  3355         demolition                USA   \n",
       "5810  8292             rubble  Columbus, Georgia   \n",
       "1228  1769  buildings burning   Washington, D.C.   \n",
       "1853  2664              crush                NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "6450  erdogans bloody gambit on july a suicide bombi...       1  \n",
       "2331  epa begins demolition of homes in toxic area b...       1  \n",
       "5810  refuse to let my life be reduced to rubble whe...       0  \n",
       "1228  watching xela firefighters struggle to save bu...       1  \n",
       "1853                               ina buted girl crush       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the 'Location' column.\n",
    "Because there are so many unique values, as mentioned earlier, I chose not to use the 'location' column. I dropped it from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df.drop(columns = 'location', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before saving to file, check for empty values in the text field.\n",
    "It's possible, after cleaning, that some 'text' fields are empty, so I checked for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>7295</td>\n",
       "      <td>nuclear reactor</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          keyword text  target\n",
       "5115  7295  nuclear reactor            0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.loc[(cleaned_train_df['text'].isna()==True) | (cleaned_train_df['text'] == '')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one. There isn't any other useful information in that tweet, so I chose to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df.drop(index = 5115, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, keyword, text, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df.loc[(cleaned_train_df['text'].isna()==True) | (cleaned_train_df['text'] == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df.to_csv(path_or_buf = '/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/cleaned_train.csv',\n",
    "                        index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmed copy of the cleaned training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df = cleaned_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df['text'] = stemmed_train_df['text'].apply(lambda x: helpers.text_normalize(x, stem_it = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>8425</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>two hour of sandstorm remix all merg togeth no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>6714</td>\n",
       "      <td>lava</td>\n",
       "      <td>contempl go to chili just to get a molten lava...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>6788</td>\n",
       "      <td>lightning</td>\n",
       "      <td>world war ii book lightn joe an autobiographi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>8673</td>\n",
       "      <td>sinkhole</td>\n",
       "      <td>damn that sinkhol on sunset</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>885</td>\n",
       "      <td>bioterrorism</td>\n",
       "      <td>if collud take wht f auth make her look blk wb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       keyword                                               text  \\\n",
       "5899  8425     sandstorm  two hour of sandstorm remix all merg togeth no...   \n",
       "4722  6714          lava  contempl go to chili just to get a molten lava...   \n",
       "4770  6788     lightning  world war ii book lightn joe an autobiographi ...   \n",
       "6071  8673      sinkhole                        damn that sinkhol on sunset   \n",
       "614    885  bioterrorism  if collud take wht f auth make her look blk wb...   \n",
       "\n",
       "      target  \n",
       "5899       0  \n",
       "4722       0  \n",
       "4770       1  \n",
       "6071       1  \n",
       "614        1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df.to_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/stemmed_train.csv',\n",
    "                        index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized copy of the cleaned training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train_df = cleaned_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train_df['text'] = lemmatized_train_df['text'].apply(lambda x: helpers.text_normalize(x, lemmatize_it = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>9272</td>\n",
       "      <td>sunk</td>\n",
       "      <td>im getting a car wow it hasnt sunk in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>7984</td>\n",
       "      <td>razed</td>\n",
       "      <td>at least you were sincere</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>4507</td>\n",
       "      <td>emergency</td>\n",
       "      <td>survival kit whistle fire starter wire saw cre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>7126</td>\n",
       "      <td>military</td>\n",
       "      <td>were hiring read about our latest job opening ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>7068</td>\n",
       "      <td>meltdown</td>\n",
       "      <td>omg i remember the meltdown the day i did her ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    keyword                                               text  \\\n",
       "6485  9272       sunk              im getting a car wow it hasnt sunk in   \n",
       "5596  7984      razed                          at least you were sincere   \n",
       "3136  4507  emergency  survival kit whistle fire starter wire saw cre...   \n",
       "4995  7126   military  were hiring read about our latest job opening ...   \n",
       "4958  7068   meltdown  omg i remember the meltdown the day i did her ...   \n",
       "\n",
       "      target  \n",
       "6485       0  \n",
       "5596       1  \n",
       "3136       0  \n",
       "4995       0  \n",
       "4958       0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train_df.to_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/lemmatized_train.csv',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform same cleaning steps on test data as were performed on the training data (except removing any records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df['text'] = cleaned_test_df['text'].apply(lambda x: convert_abbrev(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df['text'] = cleaned_test_df['text'].apply(lambda x: helpers.text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keyword = cleaned_test_df.loc[cleaned_test_df['keyword'].isna() == True].index\n",
    "cleaned_test_df['keyword'].loc[no_keyword] = 'no_keyword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df['keyword'] = cleaned_test_df['keyword'].apply(lambda x: helpers.text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df.drop(columns = 'location', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My models performed best on the lemmatized training data, so I lemmatize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df['text'] = cleaned_test_df['text'].apply(lambda x: helpers.text_normalize(x, lemmatize_it = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>8115</td>\n",
       "      <td>rescued</td>\n",
       "      <td>niger state</td>\n",
       "      <td>three suspect in police net for kidnapping tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>7820</td>\n",
       "      <td>quarantine</td>\n",
       "      <td></td>\n",
       "      <td>quarantine enforced isolation to prevent conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>9871</td>\n",
       "      <td>traumatised</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>im so traumatised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>7347</td>\n",
       "      <td>obliterate</td>\n",
       "      <td>usa</td>\n",
       "      <td>watch sarah palin obliterate planned parenthoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>417</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>apocalypse no why artist should not go into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword     location  \\\n",
       "2428  8115      rescued  niger state   \n",
       "2340  7820   quarantine                \n",
       "2985  9871  traumatised   nolocation   \n",
       "2195  7347   obliterate          usa   \n",
       "132    417   apocalypse   nolocation   \n",
       "\n",
       "                                                   text  \n",
       "2428  three suspect in police net for kidnapping tra...  \n",
       "2340  quarantine enforced isolation to prevent conta...  \n",
       "2985                                  im so traumatised  \n",
       "2195  watch sarah palin obliterate planned parenthoo...  \n",
       "132   apocalypse no why artist should not go into th...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, keyword, location, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_df.loc[(cleaned_test_df['text'].isna()==True) | (cleaned_test_df['text'] == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>heard about earthquake is different city stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>there is a forest fire at spot pond goose are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>nolocation</td>\n",
       "      <td>typhoon soudelor kill in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    keyword    location  \\\n",
       "0   0  nokeyword  nolocation   \n",
       "1   2  nokeyword  nolocation   \n",
       "2   3  nokeyword  nolocation   \n",
       "3   9  nokeyword  nolocation   \n",
       "4  11  nokeyword  nolocation   \n",
       "\n",
       "                                                text  \n",
       "0                 just happened a terrible car crash  \n",
       "1  heard about earthquake is different city stay ...  \n",
       "2  there is a forest fire at spot pond goose are ...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4          typhoon soudelor kill in china and taiwan  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3263 non-null   object\n",
      " 2   location  3263 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaned_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df.to_csv('/Users/davidwalkup/ds-course/projects/Mod4/disaster_tweet_prediction/data/cleaned_test.csv',\n",
    "                       index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
